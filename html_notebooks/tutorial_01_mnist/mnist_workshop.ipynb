{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Witajcie\n",
    "\n",
    "Na tym workshopie zamiemy się rozpoznaniem odręczenie pisanych cyfr - klasycznym problemem w uczeniu maszynowym, który *wciąż* stosowany jest w wielu problemach jako podstawa do najnowszych badan naukowych. Warto poznać zbiór MNIST'a, ale przede wszystkim warto poznać techniki które pozwalają na pracę z danymi osadzonymi w przestrzeniach wielowymiarowych, takimi jak obrazy.\n",
    "\n",
    "###  Dlaczego dane wielowymiarowe? \n",
    "Czym jest obraz gdy patrzymy na niego przez większość algorytów ML? To po prostu wektor - strzałka wskazujaca na punkt w przestarzeni $R^N$, gdzie $N$ oznacza ilość wymiarów w tej przestrzeni. Ile jest wymiarów? Tyle ile pikseli * tyle ile mamy kanałów w obrazie (przeważnie 3 - RGB). Brzmi to na początku abstrakcyjnie - ale taka reprezentacja obrazu faktycznie jest stosowana w uczeniu maszynowym! Zobaczmy w takim razie jak to wygląda na przykładzie MNIST - zbioru odręcznie pisanych cyfr, na monochromatycznych obrazkach o rozmiarach 28 na 28 pikseli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jak wyglądają cyferki MNISTa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show 2D matrices as tiles (takes 4D `examples` tensor with dims: rows x cols x tile_height x tile_width as input)\n",
    "def tiles(examples):\n",
    "    rows_count = examples.shape[0]\n",
    "    cols_count = examples.shape[1]\n",
    "    tile_height = examples.shape[2]\n",
    "    tile_width = examples.shape[3]\n",
    "    \n",
    "    space_between_tiles = 2\n",
    "    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,  \n",
    "                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles))\n",
    "    img_matrix.fill(np.nan)\n",
    "\n",
    "    # TODO: fill in loops that copy 2D slices from 4D tensor into 2D grid to display\n",
    "    \n",
    "    return img_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mnist\n",
    "digits = np.reshape(mnist.train_images()[:12*24], newshape=(12, 24, 28, 28))\n",
    "\n",
    "img = tiles(digits)\n",
    "plt.matshow(img, cmap='gray', interpolation='none')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = mnist.train_images().astype(np.float32) / 255.0\n",
    "y = mnist.train_labels()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape `X` so that the last two dimensions are collapsed into single dimension\n",
    "# X = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wbudujmy nasze obserwacje ze zbioru MNIST w niskowymiarową przestrzeń "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ciężko nam sobie wyobrazić jak wyglądają takie obserwacje w 784 wymiarach - dlatego powstały techniki redukcji wymiarowości, zachowujące jak najwięcej informacji o wzajemnym położeniu punktów w oryginalnej przestrzeni. Na początku zobaczymy jak działa klasyczna metoda (dość prosta, bo liniowa), polegająca na zmianie układu współrzędnych tak, by na kolejnych osiach zachowywać jak najwięcej wariancji z oryginalnego zbioru - **Principal Components Analysis**, czyli mówiąc krótko - **PCA**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_2d_mnist_scatter(X, y):\n",
    "    fig, plot = plt.subplots()\n",
    "    fig.set_size_inches(16, 16)\n",
    "    plt.prism()\n",
    "\n",
    "    # TODO: plot each digit observations at given coordinates with seperate scatter and appropriate label\n",
    "    \n",
    "    plot.set_xticks(())\n",
    "    plot.set_yticks(())\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAMPLES_LIMIT = 2000\n",
    "X_small = X[:SAMPLES_LIMIT]\n",
    "y_small = y[:SAMPLES_LIMIT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use PCA function to embed `X_small` in two dimensions. Store the result in `X_pca_embedded`.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# pca =  ???\n",
    "# X_pca_embedded = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pca_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_2d_mnist_scatter(X_pca_embedded, y_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile wariancji udało się zachować w naszych dwóch pierwszych składowych głównych? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, rzut z 784 wymiarów zachował zadziwiająco dużo informacji, utrzymując poszczególne obserwacje we względnie zwartych grupach. W dwóch pierwszych składowych głównych udało nam się zachować kolejno 10.0% i 7.4% wariancji z oryginalnych danych - dużo straciliśmy, ale zachowanie 17.4% wariancji przy pozostawieniu tylko 0.26% ze wszystkich wymiarów to i tak duże osiągnięcie. \n",
    "\n",
    "Czy możemy lepiej? Oczywiście! Musimy jednak skorzystać z modelu, który będzie w stanie zamodelować nieliniowe relacje w danych - znajdziemy tzw. dwuwymiarowy manifold na którym układają sie dane w przestrzeni 784 wymiarowej stosując technikę **t-distributed Stochastic Neighbour Embedding**, znaną pod skrótem **t-SNE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use t-SNE from sklearn package to embed `X_small` in two dimensions. Store the result in `X_tsne_embedded`.\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = ???\n",
    "# X_tsne_embedded = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tsne_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_2d_mnist_scatter(X_tsne_embedded, y_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli mamy zainstalowane plotly, spróbujmy z interaktywnym wykresem w 3 wymiarach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "def plot_3d_mnist_plotly_scatter(X, y):\n",
    "    def make_trace(i):\n",
    "        digit_indeces = y == i\n",
    "        return go.Scatter3d(\n",
    "            x=X[digit_indeces, 0],\n",
    "            y=X[digit_indeces, 1],\n",
    "            z=X[digit_indeces, 2],\n",
    "            mode='markers',\n",
    "            name=str(i),\n",
    "            marker=dict(\n",
    "                color=i,\n",
    "                colorscale='Jet',\n",
    "                size=4,\n",
    "                symbol='circle',\n",
    "                line=dict(\n",
    "                    color='rgb(204, 204, 204)',\n",
    "                    width=1)))\n",
    "        \n",
    "    traces = [make_trace(i) for i in range(10)]\n",
    "    \n",
    "    layout = go.Layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Use t-SNE from sklearn package to embed `X_small` in three dimensions. Store the result in `X_tsne_3d_embedded`.\n",
    "\n",
    "# tsne_3d = ??? \n",
    "# X_tsne_3d_embedded = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tsne_3d_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_3d_mnist_plotly_scatter(X_tsne_3d_embedded, y_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spróbujmy sklasyfikować obserwacje ze zbioru MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, zaawansowane techniki redukcji wymiarowości pozwalają na wyseparowanie wyraźnych klastrów naszych obserwacji z 784 wymiarowej przestrzeni. Skoro tak, nie powinniśmy mieć większego problemu z wytrenowaniem klasyfikatora, który poradzi sobie z zadaniem rozpoznawiania cyferek na obrazkach. \n",
    "\n",
    "Do tego celu skorzystamy z klasyfikatora opartego o **Support Vector Machines (SVM)**, który choć jest modelem liniowym, potrafi sobie poradzić ze znalezieniem złożonego manifoldu na którym leżą obserwacje przez tzw. **kernel trick** - czyli transformacje przestrzeni w taki sposób, aby obserwacje były separowalne liniowo. My skorzystamy z tak zwanego **Gaussian Kernel'a**, znanego inaczej **Radial Basis Function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SAMPLES_LIMIT=10000\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:SAMPLES_LIMIT], y[:SAMPLES_LIMIT], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "classifier = svm.SVC(C=1, gamma=0.001)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print(\"Classification report for classifier {}:\\n{}\\n\".format(\n",
    "    classifier, metrics.classification_report(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W macierzy pomyłek możemy zauważyć które klasy są mylone z którymi. Widzimy, że niektóre klasy mylą się z innymi znacznie częściej od pozostałych. Czy jest w tym jakaś zależność? Czy stoi za tym jakaś reguła? Jak to się ma do naszych rzutów w przestrzeń niskowymiarową za pomocą t-SNE?\n",
    "\n",
    "Zobaczmy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(y_test, predicted)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A może jakieś proste podejście z sieciami konwolucyjnymi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasze podejście gubi dość istotną informację o modalności na której pracujemy! Obraz ma dość specyficzną strukturę - piksele obok siebie są skorelowane i podobne wzorce występują w różnych fragmentach obrazu. Możemy skorzystać z tej wiedzy - jeżeli zbudujemy model tak, aby uwzględniał to co wiem *a-priori* o naszych danych, powinien sobie poradzić lepiej w zadaniu klasyfikacji. \n",
    "\n",
    "Dokładnie to robią **sieci konwolucyjne**, znane też jako **CNN's (convolutional neural nets)**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_placeholder = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_placeholder = tf.placeholder(tf.int32, shape=[None])\n",
    "y_onehot = tf.one_hot(y_placeholder, 10, 1.0, 0.0)\n",
    "\n",
    "x_image = tf.reshape(x_placeholder, [-1,28,28,1])\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# first layer convolutional filters will have 5x5x1 dimensions, and theres 32 of them\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# first convnet layer (takes [?, 28, 28, 1] tensor as input, output [?, 14, 14, 32] due to 2x2 pooling)\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: define parameter variables so that we have a correct filter tensor\n",
    "\n",
    "# second layer convolutional filters will have 5x5x32 dimensions (notice depth increase!) - there should be 64 filters\n",
    "# W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "# b_conv2 = bias_variable([64])\n",
    "\n",
    "# second convnet layer (takes [?, 28, 28, 1] tensor as input, output [?, 14, 14, 32] due to 2x2 pooling)\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# then we apply first fully connected layer at the output\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# then some dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# and finally layer that computes logits for softmax layer\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "correct = tf.equal(tf.argmax(logits, 1), tf.argmax(y_onehot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_onehot, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy_loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "def chunks(seq, size):\n",
    "    return [seq[pos:pos + size] for pos in range(0, len(seq), size)]\n",
    "\n",
    "def cycle_chunks(seq, size):\n",
    "    return cycle(chunks(seq, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "BATCHES_COUNT = 500\n",
    "for i, (batch, labels) in zip(range(BATCHES_COUNT), \n",
    "                              zip(cycle_chunks(X_train, BATCH_SIZE), \n",
    "                                  cycle_chunks(y_train, BATCH_SIZE))):\n",
    "    if i % 10 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x_placeholder:batch, y_placeholder: labels, keep_prob: 1.0})\n",
    "        print(\"Step {0}, training accuracy {1:>2.2f}\".format(i, 100 * train_accuracy))\n",
    "    train_step.run(feed_dict={x_placeholder: batch, y_placeholder: labels, keep_prob: 0.5})\n",
    "\n",
    "print(\"Test accuracy {0:>2.2f}\".format(\n",
    "    100 * accuracy.eval(feed_dict={x_placeholder: X_test, y_placeholder: y_test, keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bazowaliśmy na części zbioru MNIST - dość łatwo możemy zwiększyć *accuracy* do poziomy około 98%. W praktyce najnowsze metody znacznie przekraczają poziom 99%. Najważnieszy wniosek jest taki, że dość łatwo udało nam się wykorzystać informację, którą znaliśmy *a-priori*, o strukturze danych do sformułowania rozwiązania dającego lepsze rezultaty. No cóż, pewnie dlatego w uczeniu maszynowym mamy tak wiele różnych modeli - po prostu każda modalność rządzi się swoimi prawami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dzięki za udział w workshopie, do zobaczenia na hackatonie!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sniug]",
   "language": "python",
   "name": "conda-env-sniug-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
